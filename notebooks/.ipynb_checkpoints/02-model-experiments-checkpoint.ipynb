{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiments\n",
    "\n",
    "In this notebook, we will experiment with different machine learning models and their configurations using the Australian Student Performance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from src.data.loader import load_data\n",
    "from src.data.cleaning import clean_data, one_hot_encode\n",
    "from src.data.balancing import balance_dataset\n",
    "from src.data.split import split_data\n",
    "from src.models.model_factory import create_model\n",
    "from src.training.trainer import Trainer\n",
    "from src.evaluation.evaluate import evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "load-and-clean-data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Student ID', 'University ID', 'Age', 'Year of Study', 'GPA',\n",
      "       'High School GPA', 'Entrance Exam Score', 'Attendance Rate',\n",
      "       'Participation in Extracurricular Activities', 'Part-time Job',\n",
      "       'Hours of Study per Week', 'Family Income',\n",
      "       'Distance from Home to University', 'Internet Access at Home',\n",
      "       'Library Usage', 'Access to Academic Resources', 'Scholarship',\n",
      "       'Financial Aid', 'Tutor Support', 'Counseling Services',\n",
      "       'Hours of Sleep per Night', 'Exercise Frequency', 'Peer Support',\n",
      "       'Use of Online Learning Platforms', 'Project/Assignment Scores',\n",
      "       'Midterm Exam Scores', 'Final Exam Scores',\n",
      "       'Attendance at Office Hours', 'Group Work Participation',\n",
      "       'Research Involvement', 'Internship Experience', 'Peer Reviews',\n",
      "       'Academic Advising', 'Core Course Average',\n",
      "       'Extracurricular Participation', 'Peer Evaluations',\n",
      "       'University Name_University B', 'University Name_University C',\n",
      "       'Gender_M', 'Major_CE', 'Major_CS', 'Major_EE', 'Major_ME',\n",
      "       'Parental Education Level_Doctorate',\n",
      "       'Parental Education Level_High School',\n",
      "       'Parental Education Level_Master', 'Accommodation Type_Off-campus',\n",
      "       'Accommodation Type_With family', 'Health Condition_Fair',\n",
      "       'Health Condition_Good', 'Health Condition_Poor',\n",
      "       'Mental Health Status_Fair', 'Mental Health Status_Good',\n",
      "       'Mental Health Status_Poor', 'Transportation Mode_Car',\n",
      "       'Transportation Mode_Public Transport', 'Transportation Mode_Walking',\n",
      "       'Diet Quality_Fair', 'Diet Quality_Good', 'Diet Quality_Poor',\n",
      "       'Social Integration_Fair', 'Social Integration_Good',\n",
      "       'Social Integration_Poor', 'Language Proficiency_Fair',\n",
      "       'Language Proficiency_Good', 'Language Proficiency_Poor',\n",
      "       'Class Participation_Fair', 'Class Participation_Good',\n",
      "       'Class Participation_Poor', 'Learning Style_Kinesthetic',\n",
      "       'Learning Style_Reading/Writing', 'Learning Style_Visual',\n",
      "       'Study Environment_Fair', 'Study Environment_Good',\n",
      "       'Study Environment_Poor', 'Performance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load and clean the data\n",
    "data = load_data('../data/raw/Australian_Student_PerformanceData (ASPD24).csv')\n",
    "cleaned_data = clean_data(data)\n",
    "performance = cleaned_data['Performance']\n",
    "cleaned_data = cleaned_data.drop('Performance', axis=1)\n",
    "cleaned_data = one_hot_encode(cleaned_data)\n",
    "cleaned_data['Performance'] = performance\n",
    "print(cleaned_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "balance-and-split-data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'Satisfactory': 23996, 'Needs Improvement': 20260, 'Good': 16050, 'Poor': 11967, 'Excellent': 8017})\n",
      "Balanced dataset shape: Counter({'Satisfactory': 23996, 'Needs Improvement': 23996, 'Good': 23996, 'Excellent': 23996, 'Poor': 23996})\n"
     ]
    }
   ],
   "source": [
    "# Balance and split the data\n",
    "balanced_data = balance_dataset(cleaned_data, target_column='Performance')\n",
    "train_data, val_data, test_data = split_data(balanced_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "experiment-with-models"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression Accuracy: 0.20032387121356449\n",
      "decision_tree Accuracy: 0.2803867403314917\n",
      "random_forest Accuracy: 0.3836445037149933\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different models\n",
    "models = ['logistic_regression', 'decision_tree', 'random_forest', 'svm']\n",
    "results = {}\n",
    "\n",
    "for model_name in models:\n",
    "    model = create_model(model_name)\n",
    "    X_train = train_data.drop('Performance', axis=1)\n",
    "    y_train = train_data['Performance']\n",
    "    model.fit(X_train, y_train)\n",
    "    val_predictions = model.predict(val_data.drop('Performance', axis=1))\n",
    "    accuracy = accuracy_score(val_data['Performance'], val_predictions)\n",
    "    results[model_name] = accuracy\n",
    "    print(f'{model_name} Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-best-model"
   },
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_model = create_model(best_model_name)\n",
    "train_model(best_model, train_data)\n",
    "test_predictions = best_model.predict(test_data.drop('target', axis=1))\n",
    "test_report = classification_report(test_data['target'], test_predictions)\n",
    "print(f'Best Model: {best_model_name}')\n",
    "print(test_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspd24-ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
