{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiments\n",
    "\n",
    "In this notebook, we will experiment with different machine learning models and their configurations using the Australian Student Performance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from src.data.loader import load_data\n",
    "from src.data.cleaning import clean_data, one_hot_encode\n",
    "from src.data.balancing import balance_dataset\n",
    "from src.data.split import split_data\n",
    "from src.models.model_factory import create_model\n",
    "from src.training.trainer import Trainer\n",
    "from src.evaluation.evaluate import evaluate_model\n",
    "from scripts.run_tuning import get_param_grid\n",
    "from src.training.hyperparameter_tuning import HyperparameterTuner\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the data\n",
    "data = load_data('../data/raw/Australian_Student_PerformanceData (ASPD24).csv')\n",
    "cleaned_data = clean_data(data)\n",
    "\n",
    "# Fix column names with leading/trailing spaces\n",
    "cleaned_data.columns = cleaned_data.columns.str.strip()\n",
    "\n",
    "\n",
    "# Balance and split the data\n",
    "#balanced_data = balance_dataset(cleaned_data, target_column='Performance') # Note -> we dont really need balancing here as the differences in target value counts are not that large\n",
    "\n",
    "# split data\n",
    "train_data, val_data, test_data = split_data(cleaned_data, test_size=0.2, val_size=0.1, random_state=42) \n",
    "\n",
    "# remove imperfections\n",
    "for df in [train_data, val_data, test_data]:\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "# encoding according to actual feature types\n",
    "drop_columns = [\"Student ID\", \"University ID\"] # those are not needed (noise)\n",
    "\n",
    "numeric_features = [\n",
    "    \"Age\",\n",
    "    \"Year of Study\",\n",
    "    \"GPA\",\n",
    "    \"High School GPA\",\n",
    "    \"Entrance Exam Score\",\n",
    "    \"Attendance Rate\",\n",
    "    \"Participation in Extracurricular Activities\",\n",
    "    \"Part-time Job\",\n",
    "    \"Hours of Study per Week\",\n",
    "    \"Family Income\",\n",
    "    \"Distance from Home to University\",\n",
    "    \"Internet Access at Home\",\n",
    "    \"Library Usage\",\n",
    "    \"Access to Academic Resources\",\n",
    "    \"Scholarship\",\n",
    "    \"Financial Aid\",\n",
    "    \"Tutor Support\",\n",
    "    \"Counseling Services\",\n",
    "    \"Hours of Sleep per Night\",\n",
    "    \"Exercise Frequency\",\n",
    "    \"Peer Support\",\n",
    "    \"Use of Online Learning Platforms\",\n",
    "    \"Project/Assignment Scores\",\n",
    "    \"Midterm Exam Scores\",\n",
    "    \"Final Exam Scores\",\n",
    "    \"Attendance at Office Hours\",\n",
    "    \"Group Work Participation\",\n",
    "    \"Research Involvement\",\n",
    "    \"Internship Experience\",\n",
    "    \"Peer Reviews\",\n",
    "    \"Academic Advising\",\n",
    "    \"Core Course Average\",\n",
    "    \"Extracurricular Participation\",\n",
    "    \"Peer Evaluations\"\n",
    "]\n",
    "\n",
    "ordinal_features = [\n",
    "    \"Health Condition\",\n",
    "    \"Mental Health Status\",\n",
    "    \"Diet Quality\",\n",
    "    \"Social Integration\",\n",
    "    \"Language Proficiency\",\n",
    "    \"Study Environment\",\n",
    "    \"Class Participation\"\n",
    "]\n",
    "\n",
    "ordinal_categories = [\n",
    "    [\"Poor\", \"Fair\", \"Good\", \"Excellent\"],  # Health Condition\n",
    "    [\"Poor\", \"Fair\", \"Good\", \"Excellent\"],  # Mental Health Status\n",
    "    [\"Poor\", \"Fair\", \"Good\", \"Excellent\"],  # Diet Quality\n",
    "    [\"Poor\", \"Fair\", \"Good\", \"Excellent\"],  # Social Integration\n",
    "    [\"Poor\", \"Fair\", \"Good\", \"Excellent\"],  # Language Proficiency\n",
    "    [\"Poor\", \"Fair\", \"Good\", \"Excellent\"],  # Study Environment\n",
    "    [\"Poor\", \"Fair\", \"Good\", \"Excellent\"]   # Class Participation\n",
    "]\n",
    "\n",
    "nominal_features = [\n",
    "    \"University Name\",\n",
    "    \"Gender\",\n",
    "    \"Major\",\n",
    "    \"Parental Education Level\",\n",
    "    \"Accommodation Type\",\n",
    "    \"Transportation Mode\",\n",
    "    \"Learning Style\"\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"ord\", OrdinalEncoder(categories=ordinal_categories), ordinal_features),\n",
    "        (\"nom\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), nominal_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "load-and-clean-data"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_data.drop(columns=[\"Performance\"])\n",
    "y_train = train_data[\"Performance\"]\n",
    "X_val = val_data.drop(columns=[\"Performance\"])\n",
    "y_val = val_data[\"Performance\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "experiment-with-models"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tuning logistic_regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different models\n",
    "\n",
    "models = [\"logistic_regression\", \"decision_tree\", \"random_forest\", \"svm\"]\n",
    "results = {}\n",
    "\n",
    "X_train = train_data.drop(columns=[\"Performance\"])\n",
    "y_train = train_data[\"Performance\"]\n",
    "X_val = val_data.drop(columns=[\"Performance\"])\n",
    "y_val = val_data[\"Performance\"]\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"\\n Tuning {model_name}...\")\n",
    "\n",
    "    config = get_param_grid(model_name)\n",
    "\n",
    "    # Build full pipeline\n",
    "    model_pipeline = Pipeline([\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"clf\", config[\"model\"])\n",
    "    ])\n",
    "\n",
    "    tuner = HyperparameterTuner(\n",
    "        model=model_pipeline,\n",
    "        param_grid={f\"clf__{k}\": v for k, v in config[\"params\"].items()},\n",
    "        scoring=\"accuracy\",\n",
    "        cv=3,\n",
    "        n_iter=20,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    best_model, best_params, best_score = tuner.tune(X_train, y_train, method=\"random\")\n",
    "\n",
    "    print(\"Best Params:\", best_params)\n",
    "    print(\"Best CV Score:\", best_score)\n",
    "\n",
    "    val_preds = best_model.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, val_preds)\n",
    "\n",
    "    print(f\"Validation Accuracy ({model_name}):\", val_acc)\n",
    "\n",
    "    results[model_name] = (best_model, val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "evaluate-best-model"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m best_model_name = \u001b[38;5;28mmax\u001b[39m(results, key=results.get)\n\u001b[32m      3\u001b[39m best_model = create_model(best_model_name)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrain_model\u001b[49m(best_model, train_data)\n\u001b[32m      5\u001b[39m test_predictions = best_model.predict(test_data.drop(\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m, axis=\u001b[32m1\u001b[39m))\n\u001b[32m      6\u001b[39m test_report = classification_report(test_data[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m], test_predictions)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_model = create_model(best_model_name)\n",
    "train_model(best_model, train_data)\n",
    "test_predictions = best_model.predict(test_data.drop('target', axis=1))\n",
    "test_report = classification_report(test_data['target'], test_predictions)\n",
    "print(f'Best Model: {best_model_name}')\n",
    "print(test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
